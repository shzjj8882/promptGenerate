#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DMUè¡¨æ ¼æ•°æ®æå–å™¨ - å…¨åŠŸèƒ½ç‰ˆæœ¬
ä»Difyå·¥ä½œæµä¸­æå–çš„DMUæ•°æ®æå–é€»è¾‘
"""
import re
import json
import datetime
from typing import Dict, Any, List, Optional


class BusinessException(Exception):
    """
    ä¸šåŠ¡å¼‚å¸¸ç±»ï¼Œç”¨äºå¤„ç†ä¸šåŠ¡é€»è¾‘é”™è¯¯
    """
    def __init__(self, message: str, error_code: str = "BUSINESS_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(self.message)


def clean_markdown_format(markdown_text: str) -> str:
    """
    æ¸…ç†Markdownæ ¼å¼ï¼Œä¿ç•™çº¯æ–‡æœ¬å†…å®¹
    """
    # ç§»é™¤ä»£ç å—
    markdown_text = re.sub(r'```[\s\S]*?```', '', markdown_text)
    
    # ç§»é™¤è¡Œå†…ä»£ç 
    markdown_text = re.sub(r'`([^`]+)`', r'\1', markdown_text)
    
    # ç§»é™¤ç²—ä½“æ ‡è®°
    markdown_text = re.sub(r'\*\*([^*]+)\*\*', r'\1', markdown_text)
    markdown_text = re.sub(r'__([^_]+)__', r'\1', markdown_text)
    
    # ç§»é™¤æ–œä½“æ ‡è®°
    markdown_text = re.sub(r'\*([^*]+)\*', r'\1', markdown_text)
    markdown_text = re.sub(r'_([^_]+)_', r'\1', markdown_text)
    
    # ç§»é™¤åˆ é™¤çº¿
    markdown_text = re.sub(r'~~([^~]+)~~', r'\1', markdown_text)
    
    # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™é“¾æ¥æ–‡æœ¬
    markdown_text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', markdown_text)
    
    # ç§»é™¤å›¾ç‰‡æ ‡è®°
    markdown_text = re.sub(r'!\[([^\]]*)\]\([^)]+\)', r'\1', markdown_text)
    
    # ç§»é™¤å¼•ç”¨æ ‡è®°
    markdown_text = re.sub(r'^>\s*', '', markdown_text, flags=re.MULTILINE)
    
    # ç§»é™¤åˆ—è¡¨æ ‡è®°
    markdown_text = re.sub(r'^[\s]*[-*+]\s+', '', markdown_text, flags=re.MULTILINE)
    markdown_text = re.sub(r'^[\s]*\d+\.\s+', '', markdown_text, flags=re.MULTILINE)
    
    # ç§»é™¤æ ‡é¢˜æ ‡è®°
    markdown_text = re.sub(r'^#{1,6}\s+', '', markdown_text, flags=re.MULTILINE)
    
    # ç§»é™¤æ°´å¹³åˆ†å‰²çº¿
    markdown_text = re.sub(r'^[-*_]{3,}$', '', markdown_text, flags=re.MULTILINE)
    
    # ç§»é™¤è¡¨æ ¼æ ¼å¼ï¼Œä½†ä¿ç•™è¡¨æ ¼å†…å®¹
    markdown_text = clean_table_format(markdown_text)
    
    # ç§»é™¤HTMLæ ‡ç­¾
    markdown_text = re.sub(r'<[^>]+>', '', markdown_text)
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
    markdown_text = re.sub(r'\n\s*\n\s*\n', '\n\n', markdown_text)
    
    # ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
    markdown_text = '\n'.join(line.strip() for line in markdown_text.split('\n'))
    
    return markdown_text.strip()


def clean_table_format(text: str) -> str:
    """
    æ¸…ç†è¡¨æ ¼æ ¼å¼ï¼Œä½†ä¿ç•™è¡¨æ ¼å†…å®¹ç»“æ„
    """
    lines = text.split('\n')
    cleaned_lines = []
    
    # å®šä¹‰è¯„åˆ†å­—æ®µçš„å…³é”®è¯
    rating_fields = ['å½±å“åŠ›', 'ç†Ÿæ‚‰åº¦', 'æ”¯æŒåº¦', 'influence', 'familiarity', 'support']
    
    # å…ˆæ‰«ææ‰€æœ‰è¡Œï¼Œæ‰¾åˆ°è¡¨å¤´å¹¶ç¡®å®šè¯„åˆ†åˆ—
    rating_columns = set()
    for line in lines:
        if '|' in line and not re.match(r'^\|.*[-=]{2,}.*\|$', line.strip()):
            # ç§»é™¤é¦–å°¾çš„|
            line = line.strip()
            if line.startswith('|'):
                line = line[1:]
            if line.endswith('|'):
                line = line[:-1]
            
            cells = [cell.strip() for cell in line.split('|')]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨å¤´ï¼ˆåŒ…å«è¯„åˆ†å­—æ®µå…³é”®è¯ï¼‰
            if any(field in cell for cell in cells for field in rating_fields):
                for i, cell in enumerate(cells):
                    if any(field in cell for field in rating_fields):
                        rating_columns.add(i)
                break
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†è¡¨å¤´ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºè½¬ç½®è¡¨æ ¼ï¼ˆç¬¬ä¸€åˆ—åŒ…å«è¯„åˆ†å­—æ®µï¼‰
    if not rating_columns:
        # è½¬ç½®è¡¨æ ¼ï¼šç¬¬ä¸€åˆ—æ˜¯ç»´åº¦ï¼Œå…¶ä»–åˆ—æ˜¯æ•°æ®
        # å¦‚æœç¬¬ä¸€åˆ—åŒ…å«è¯„åˆ†å­—æ®µå…³é”®è¯ï¼Œåˆ™ç¬¬äºŒåˆ—æ˜¯è¯„åˆ†æ•°æ®
        rating_columns.add(1)  # ç¬¬äºŒåˆ—æ˜¯è¯„åˆ†æ•°æ®
    
    for line in lines:
        # è·³è¿‡åˆ†éš”è¡Œï¼ˆåŒ…å«---æˆ–===çš„è¡Œï¼‰
        if re.match(r'^\|.*[-=]{2,}.*\|$', line.strip()):
            continue
        
        # å¤„ç†è¡¨æ ¼è¡Œ
        if '|' in line:
            # ç§»é™¤é¦–å°¾çš„|
            line = line.strip()
            if line.startswith('|'):
                line = line[1:]
            if line.endswith('|'):
                line = line[:-1]
            
            # åˆ†å‰²å•å…ƒæ ¼å¹¶æ¸…ç†æ¯ä¸ªå•å…ƒæ ¼
            cells = [cell.strip() for cell in line.split('|')]
            cleaned_cells = []
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨å¤´ï¼ˆè½¬ç½®è¡¨æ ¼ï¼šåªæœ‰ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼‰
            is_header = len(cleaned_lines) == 0
            
            for i, cell in enumerate(cells):
                # åˆ¤æ–­æ˜¯å¦ä¸ºè¯„åˆ†å­—æ®µ
                if is_header:
                    # è¡¨å¤´ï¼šä¸æ˜¯è¯„åˆ†å­—æ®µ
                    is_rating_field = False
                elif i == 1 and len(cells) > 0:
                    # è½¬ç½®è¡¨æ ¼ï¼šæ£€æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦åŒ…å«è¯„åˆ†å­—æ®µå…³é”®è¯
                    first_cell = cells[0].strip()
                    is_rating_field = any(field in first_cell for field in rating_fields)
                else:
                    # å…¶ä»–æƒ…å†µï¼šä¸æ˜¯è¯„åˆ†å­—æ®µ
                    is_rating_field = False
                
                # æ¸…ç†å•å…ƒæ ¼å†…çš„Markdownæ ¼å¼
                cleaned_cell = clean_cell_content(cell, is_rating_field)
                cleaned_cells.append(cleaned_cell)
            
            # é‡æ–°ç»„åˆä¸ºè¡¨æ ¼è¡Œ
            cleaned_line = ' | '.join(cleaned_cells)
            cleaned_lines.append(cleaned_line)
        else:
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)


def count_rating_emojis(text: str) -> int:
    """
    è®¡ç®—è¯„åˆ†emojiçš„æ•°é‡ï¼Œç”¨äºå½±å“åŠ›ã€ç†Ÿæ‚‰åº¦ã€æ”¯æŒåº¦å­—æ®µ
    æ”¯æŒçš„emoji: â­ï¸ğŸ‘(æ­£æ•°), ğŸ‘(è´Ÿæ•°)
    """
    if not text:
        return 0
    
    # è®¡ç®—æ­£æ•°emojiæ•°é‡ (â­ï¸ğŸ‘)
    positive_emojis = r'â­ï¸|â­|ğŸ‘'
    positive_count = len(re.findall(positive_emojis, text))
    
    # è®¡ç®—è´Ÿæ•°emojiæ•°é‡ (ğŸ‘)
    negative_emojis = r'ğŸ‘'
    negative_count = len(re.findall(negative_emojis, text))
    
    # è®¡ç®—æœ€ç»ˆè¯„åˆ†ï¼šæ­£æ•° - è´Ÿæ•°
    emoji_count = positive_count - negative_count
    
    # å¦‚æœæ²¡æœ‰emojiï¼Œå°è¯•æå–æ•°å­—ï¼ˆåŒ…æ‹¬è´Ÿæ•°ï¼‰
    if emoji_count == 0 and positive_count == 0 and negative_count == 0:
        # æå–æ•°å­—ï¼ˆåŒ…æ‹¬è´Ÿæ•°ï¼‰
        numbers = re.findall(r'-?\d+', text)
        if numbers:
            return int(numbers[0])
    
    return emoji_count


def clean_cell_content(cell: str, is_rating_field: bool = False) -> str:
    """
    æ¸…ç†å•å…ƒæ ¼å†…å®¹
    is_rating_field: æ˜¯å¦ä¸ºè¯„åˆ†å­—æ®µï¼ˆå½±å“åŠ›ã€ç†Ÿæ‚‰åº¦ã€æ”¯æŒåº¦ï¼‰
    """
    if not cell:
        return ""
    
    # å¦‚æœæ˜¯è¯„åˆ†å­—æ®µï¼Œå…ˆè®¡ç®—emojiæ•°é‡
    if is_rating_field:
        emoji_count = count_rating_emojis(cell)
        # è¿”å›è®¡ç®—åçš„è¯„åˆ†ï¼ˆå¯èƒ½æ˜¯æ­£æ•°ã€è´Ÿæ•°æˆ–0ï¼‰
        return str(emoji_count)
    
    # å¯¹äºéè¯„åˆ†å­—æ®µï¼Œåªæ¸…ç†å¿…è¦çš„æ ¼å¼ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹
    # ç§»é™¤æ˜Ÿå·æ ‡è®°
    cell = re.sub(r'\*\*([^*]+)\*\*', r'\1', cell)
    cell = re.sub(r'\*([^*]+)\*', r'\1', cell)
    
    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
    cell = re.sub(r'\s+', ' ', cell)
    cell = re.sub(r'\n+', ' ', cell)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    cell = cell.strip()
    
    return cell


def extract_dmu_table_section(markdown_text: str) -> str:
    """
    æå–"å•†æœºåˆ†æè¡¨"æ ‡é¢˜ä¸‹ï¼Œè¿ç»­çš„"|"è¡¨æ ¼è¡Œï¼ˆç¬¬ä¸€è¡Œå’Œç¬¬äºŒè¡Œéƒ½æ˜¯è¡¨å¤´ï¼‰
    """
    # 1. æ‰¾åˆ°"å•†æœºåˆ†æè¡¨"æ ‡é¢˜è¡Œ
    m = re.search(r'^\s*###\s*.*å•†æœºåˆ†æè¡¨.*$', markdown_text, re.MULTILINE)
    if not m:
        return ""
    start = m.end()
    # 2. ä»æ ‡é¢˜ä¸‹æ–¹å¼€å§‹ï¼Œæ”¶é›†è¿ç»­çš„"|"è¡Œï¼ˆè¡¨æ ¼è¡Œï¼‰
    lines = markdown_text[start:].splitlines()
    table_lines = []
    for line in lines:
        if "|" in line:
            table_lines.append(line)
        elif table_lines:  # å·²ç»å¼€å§‹æ”¶é›†ï¼Œé‡åˆ°éè¡¨æ ¼è¡Œå°±åœæ­¢
            break
    return "\n".join(table_lines)


def extract_table_as_matrix(text: str) -> List[List[str]]:
    """
    ä»æ¸…ç†åçš„æ–‡æœ¬ä¸­æå–è¡¨æ ¼ä¸ºäºŒç»´æ•°ç»„
    """
    lines = [line for line in text.split('\n') if '|' in line]
    table = []
    for line in lines:
        cells = [cell.strip() for cell in line.split('|')]
        table.append(cells)
    # è¿‡æ»¤æ‰é•¿åº¦ä¸ä¸€è‡´çš„è¡Œ
    max_len = max(len(row) for row in table) if table else 0
    table = [row for row in table if len(row) == max_len]
    return table


def match_dim(cell: str, dmu_dims: List[str], dim_alias: dict) -> Optional[str]:
    for std_dim in dmu_dims:
        for alias in dim_alias[std_dim]:
            if alias in cell:
                return std_dim
    return None


def extract_opportunity_score_from_cleaned(markdown_text: str) -> Dict[str, Any]:
    """æå–å•†æœºå¤©å¹³åˆ†æ•°"""
    import re
    
    # 1. å°è¯•æå– ### å•†æœºå¤©å¹³ æ ¼å¼
    section = extract_section_by_title(markdown_text, "å•†æœºå¤©å¹³")
    if section:
        calculation = score = tendency = None
        for line in section.splitlines():
            line = line.strip().lstrip("*#- ").strip()
            if line.startswith("å…¬å¼/è¡¨è¾¾å¼"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                calculation = val.strip()
            elif line.startswith("æ€»åˆ†"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                score_str = val.replace("åˆ†", "").strip()
                if score_str.isdigit():
                    score = int(score_str.strip())
            elif line.startswith("å€¾å‘æè¿°"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                tendency = val.strip("ï¼ˆï¼‰() ").strip()
        if calculation and score is not None and tendency:
            full_content = extract_content_between_sections(markdown_text, "å•†æœºå¤©å¹³", "å•†æœºæ¨è¿›å»ºè®®", "å•†æœºå†³ç­–")
            result = {
                "calculation": calculation.strip(),
                "score": score,
                "tendency": tendency.strip()
            }
            if full_content:
                result["full_content"] = full_content
            return result
    
    # 2. å°è¯•æå– **å•†æœºå¤©å¹³** æ ¼å¼
    pattern = r'\*\*å•†æœºå¤©å¹³\*\*([\s\S]*?)(?=\*\*|###|\Z)'
    match = re.search(pattern, markdown_text)
    if match:
        section = match.group(1)
        calculation = score = tendency = None
        for line in section.splitlines():
            line = line.strip().lstrip("*#- ").strip()
            if line.startswith("å…¬å¼/è¡¨è¾¾å¼"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                calculation = val.strip()
            elif line.startswith("æ€»åˆ†"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                score_str = val.replace("åˆ†", "").strip()
                if score_str.isdigit():
                    score = int(score_str.strip())
            elif line.startswith("å€¾å‘æè¿°"):
                val = line.split(":", 1)[-1] if ":" in line else line.split("ï¼š", 1)[-1]
                tendency = val.strip("ï¼ˆï¼‰() ").strip()
        if calculation and score is not None and tendency:
            full_content = extract_content_between_sections(markdown_text, "å•†æœºå¤©å¹³", "å•†æœºæ¨è¿›å»ºè®®", "å•†æœºå†³ç­–")
            result = {
                "calculation": calculation.strip(),
                "score": score,
                "tendency": tendency.strip()
            }
            if full_content:
                result["full_content"] = full_content
            return result
    
    return {"error": "æœªæ‰¾åˆ°å•†æœºå¤©å¹³åˆ†æ•°"}


def extract_section_by_title(text: str, title: str) -> str:
    """
    æå–æŒ‡å®šå¤§æ ‡é¢˜ï¼ˆå¦‚ '### å•†æœºå¤©å¹³'ï¼‰ä¸‹çš„å†…å®¹ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªåŒçº§æ ‡é¢˜æˆ–æ–‡æœ¬ç»“å°¾
    """
    import re
    m = re.search(rf'^###\s*{re.escape(title)}.*$', text, re.MULTILINE)
    if not m:
        return ""
    start = m.end()
    m2 = re.search(r'^###\s', text[start:], re.MULTILINE)
    if m2:
        section = text[start:start + m2.start()]
    else:
        section = text[start:]
    return section


def extract_content_between_sections(markdown_text: str, start_section: str, *end_sections) -> str:
    """
    æå–ä¸¤ä¸ªéƒ¨åˆ†ä¹‹é—´çš„å†…å®¹ï¼Œæ”¯æŒå¤šä¸ªç»“æŸéƒ¨åˆ†åç§°
    """
    import re
    
    # æŸ¥æ‰¾å¼€å§‹éƒ¨åˆ†çš„ä½ç½®
    start_pattern = rf'\*\*{re.escape(start_section)}\*\*'
    start_match = re.search(start_pattern, markdown_text)
    if not start_match:
        return ""
    
    # ä»å¼€å§‹éƒ¨åˆ†ç»“æŸä½ç½®å¼€å§‹æŸ¥æ‰¾
    start_pos = start_match.end()
    
    # æŸ¥æ‰¾ç»“æŸéƒ¨åˆ†çš„ä½ç½®ï¼ˆæ”¯æŒå¤šä¸ªç»“æŸéƒ¨åˆ†åç§°ï¼‰
    earliest_end_pos = len(markdown_text)
    for end_section in end_sections:
        end_pattern = rf'\*\*{re.escape(end_section)}\*\*'
        end_match = re.search(end_pattern, markdown_text[start_pos:])
        if end_match:
            end_pos = start_pos + end_match.start()
            if end_pos < earliest_end_pos:
                earliest_end_pos = end_pos
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æŸéƒ¨åˆ†ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if earliest_end_pos == len(markdown_text):
        return ""
    
    # æå–ä¸­é—´çš„å†…å®¹
    between_content = markdown_text[start_pos:earliest_end_pos].strip()
    
    return between_content


def clean_unit_fields(unit: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ¸…ç†å†³ç­–å•å…ƒçš„æ‰€æœ‰å­—æ®µï¼Œç¡®ä¿æ²¡æœ‰Noneå€¼ï¼Œæ‰€æœ‰å­—æ®µéƒ½æœ‰åˆé€‚çš„é»˜è®¤å€¼
    """
    # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„å­—æ®µåŠå…¶é»˜è®¤å€¼
    field_defaults = {
        "identity": "",
        "role": [],
        "org_needs": "",
        "personal_needs": "",
        "influence": 0,
        "support": 0,
        "familiarity": 0,
        "concern": "",
        "source": ""
    }
    
    cleaned_unit = {}
    
    # å¤„ç†æ¯ä¸ªå­—æ®µ
    for field, default_value in field_defaults.items():
        if field in unit:
            value = unit[field]
            
            # å¤„ç†Noneå€¼
            if value is None:
                cleaned_unit[field] = default_value
                continue
            
            # å¤„ç†å­—ç¬¦ä¸²å­—æ®µ
            if field in ["identity", "org_needs", "personal_needs", "concern", "source"]:
                if isinstance(value, str):
                    cleaned_value = value.strip()
                    # å¦‚æœå€¼æ˜¯'null'å­—ç¬¦ä¸²ï¼Œè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    if cleaned_value.lower() == 'null':
                        cleaned_unit[field] = default_value
                    else:
                        cleaned_unit[field] = cleaned_value if cleaned_value else default_value
                else:
                    cleaned_unit[field] = str(value).strip() if value else default_value
            
            # å¤„ç†roleå­—æ®µï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
            elif field == "role":
                if isinstance(value, str):
                    if value.lower() == 'null' or not value.strip():
                        cleaned_unit[field] = []
                    else:
                        roles = [r.strip() for r in re.split(r'[ï¼Œ,\s/]+', value) if r.strip()]
                        cleaned_unit[field] = roles
                elif isinstance(value, list):
                    # è¿‡æ»¤æ‰Noneå’Œç©ºå­—ç¬¦ä¸²
                    roles = [str(r).strip() for r in value if r and str(r).strip()]
                    cleaned_unit[field] = roles
                elif value is None:
                    cleaned_unit[field] = []
                else:
                    cleaned_unit[field] = [str(value).strip()] if str(value).strip() else []
            
            # å¤„ç†æ•°å€¼å­—æ®µï¼ˆå½±å“åŠ›ã€æ”¯æŒåº¦ã€ç†Ÿæ‚‰åº¦ï¼‰
            elif field in ["influence", "support", "familiarity"]:
                try:
                    if isinstance(value, (int, float)):
                        cleaned_unit[field] = int(value)
                    elif isinstance(value, str):
                        # å…ˆå°è¯•è®¡ç®—emojiæ•°é‡
                        emoji_count = count_rating_emojis(value)
                        if emoji_count != 0:  # ä¿®å¤ï¼šæ”¹ä¸º != 0ï¼Œå¤„ç†æ­£æ•°å’Œè´Ÿæ•°
                            cleaned_unit[field] = emoji_count
                        else:
                            # å¦‚æœæ²¡æœ‰emojiï¼Œå°è¯•æå–æ•°å­—
                            numeric_value = re.sub(r'[^\d\-]', '', value)
                            if numeric_value:
                                cleaned_unit[field] = int(numeric_value)
                            else:
                                cleaned_unit[field] = 0
                    else:
                        cleaned_unit[field] = 0
                except (ValueError, TypeError):
                    cleaned_unit[field] = 0
        else:
            # å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            cleaned_unit[field] = default_value
    
    return cleaned_unit


def extract_dmu_table_structured(markdown_text: str) -> Dict[str, Any]:
    """
    è‡ªåŠ¨è¯†åˆ«DMUè¡¨æ ¼æ–¹å‘ï¼ˆæ ‡å‡†/è½¬ç½®ï¼‰ï¼Œå¹¶è¾“å‡ºæ ‡å‡†ç»“æ„ï¼Œç¡®ä¿æ¯ä¸ªå†³ç­–å•å…ƒæœ‰'èº«ä»½'å­—æ®µï¼Œä¸”å­—æ®µåä¸ºè‹±æ–‡
    """
    # æ–°å¢ï¼šåªæå–DMUè¡¨æ ¼æ®µè½
    dmu_table_markdown = extract_dmu_table_section(markdown_text)
    if not dmu_table_markdown:
        return {"error": "æœªæ‰¾åˆ°DMUè¡¨æ ¼æ®µè½"}
    cleaned_text = clean_markdown_format(dmu_table_markdown)
    table = extract_table_as_matrix(cleaned_text)
    if not table or len(table) < 2:
        return {"error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„DMUè¡¨æ ¼"}
    dmu_dims = [
        "èº«ä»½", "è§’è‰²", "ç»„ç»‡è¯‰æ±‚", "ä¸ªäººè¯‰æ±‚", "å½±å“åŠ›", "æ”¯æŒåº¦", "ç†Ÿæ‚‰åº¦", "é¡¾è™‘"
    ]
    dim_alias = {
        "ç»„ç»‡è¯‰æ±‚": ["ç»„ç»‡è¯‰æ±‚", "å®˜æ–¹è¯‰æ±‚", "KPI"],
        "ä¸ªäººè¯‰æ±‚": ["ä¸ªäººè¯‰æ±‚", "ç§äººè¯‰æ±‚"],
        "å½±å“åŠ›": ["å½±å“åŠ›"],
        "æ”¯æŒåº¦": ["æ”¯æŒåº¦"],
        "ç†Ÿæ‚‰åº¦": ["ç†Ÿæ‚‰åº¦"],
        "é¡¾è™‘": ["é¡¾è™‘", "æ‹…å¿§"],
        "èº«ä»½": ["èº«ä»½", "å§“å", "å†³ç­–å•å…ƒ"],
        "è§’è‰²": ["è§’è‰²"]
    }
    # æ–°å¢ï¼šä¸­è‹±æ–‡æ˜ å°„
    dim_en_map = {
        "èº«ä»½": "identity",
        "è§’è‰²": "role",
        "ç»„ç»‡è¯‰æ±‚": "org_needs",
        "ä¸ªäººè¯‰æ±‚": "personal_needs",
        "å½±å“åŠ›": "influence",
        "æ”¯æŒåº¦": "support",
        "ç†Ÿæ‚‰åº¦": "familiarity",
        "é¡¾è™‘": "concern"
    }
    first_row = [cell.strip() for cell in table[0]]
    first_col = [row[0].strip() for row in table]
    row_dim_count = sum(any(dim in cell for dim in dmu_dims) for cell in first_row)
    col_dim_count = sum(any(dim in cell for dim in dmu_dims) for cell in first_col)
    is_transposed = row_dim_count > col_dim_count
    decision_units = []
    if is_transposed:
        # æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå†³ç­–å•å…ƒ
        header = first_row
        for row in table[1:]:
            unit = {}
            for i, cell in enumerate(row):
                dim = header[i].strip()
                std_dim = match_dim(dim, dmu_dims, dim_alias)
                if std_dim:
                    en_dim = dim_en_map.get(std_dim, std_dim)
                    unit[en_dim] = cell.strip()
            # å¦‚æœæ²¡æœ‰identityå­—æ®µï¼Œé»˜è®¤ç”¨ç¬¬ä¸€ä¸ªå•å…ƒæ ¼
            if "identity" not in unit and len(row) > 0:
                unit["identity"] = row[0].strip()
            if unit:
                decision_units.append(unit)
    else:
        # æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªå†³ç­–å•å…ƒ
        header = table[0]
        for col_idx in range(1, len(header)):
            unit = {"identity": header[col_idx].strip()}
            for row_idx, row in enumerate(table[1:], 1):
                dim = row[0].strip()
                std_dim = match_dim(dim, dmu_dims, dim_alias)
                if std_dim and col_idx < len(row):
                    en_dim = dim_en_map.get(std_dim, std_dim)
                    unit[en_dim] = row[col_idx].strip()
            if unit:
                decision_units.append(unit)
    
    # ä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µæ¸…ç†å‡½æ•°
    cleaned_decision_units = []
    for unit in decision_units:
        cleaned_unit = clean_unit_fields(unit)
        cleaned_decision_units.append(cleaned_unit)
    
    opportunity_score = extract_opportunity_score_from_cleaned(markdown_text)
    return {
        "decision_units": cleaned_decision_units,
        "opportunity_score": opportunity_score,
        "fabe_spi": []  # FABE/SPIå­—æ®µå§‹ç»ˆä¸ºç©ºæ•°ç»„ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
    }


def extract_company_name(text: str) -> str:
    """
    ä¼˜å…ˆä»"### å®¢æˆ·åç§°: xxx"è¡Œæå–å…¬å¸åï¼Œå¦åˆ™å›é€€åˆ°æ ‡é¢˜è¡Œ"å…¬å¸åå•†æœºåˆ†æè¡¨"
    """
    import re
    # 1. ä¼˜å…ˆåŒ¹é…"### å®¢æˆ·åç§°: xxx"
    for line in text.splitlines():
        line = line.strip()
        if line.startswith("### å®¢æˆ·åç§°:"):
            return line.replace("### å®¢æˆ·åç§°:", "").strip()
    # 2. å›é€€åˆ°åŸæœ‰æ ‡é¢˜è¡ŒåŒ¹é…
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        match = re.match(r"^[#*\s]*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()Â·]+?)\s*å•†æœºåˆ†æè¡¨", line)
        if match:
            return match.group(1).strip()
    return ""


def extract_dmu_data(llm_output: str) -> Dict[str, Any]:
    """
    ä¸»å‡½æ•° - ä»LLMè¾“å‡ºä¸­æå–DMUæ•°æ®
    """
    try:
        company_name = extract_company_name(llm_output)
        
        # 1. DMUè¡¨æ ¼ç»“æ„åŒ–
        try:
            dmu_struct = extract_dmu_table_structured(llm_output)
            decision_units = dmu_struct.get("decision_units", [])
        except Exception as e:
            decision_units = []
        
        # 2. å•†æœºå¤©å¹³
        try:
            opportunity_score = extract_opportunity_score_from_cleaned(llm_output)
            if "error" in opportunity_score:
                opportunity_score = {}
        except Exception:
            opportunity_score = {}
        
        # 3. å•†æœºæ¨è¿›å»ºè®®ï¼ˆæš‚æ—¶ä¸æå–ï¼‰
        opportunity_decision = {}
        
        # 4. FABE/SPI - ä¸å†æå–ï¼Œå§‹ç»ˆè¿”å›ç©ºæ•°ç»„ï¼ˆä¿æŒæ¥å£å…¼å®¹æ€§ï¼‰
        fabe_spi = []
        
        # 5. ç»„è£…payload
        dmu_analysis = {}
        if decision_units:
            dmu_analysis["decision_units"] = decision_units
        if opportunity_score:
            dmu_analysis["opportunity_score"] = opportunity_score
        if opportunity_decision:
            dmu_analysis["opportunity_decision"] = opportunity_decision
        # FABE/SPIå­—æ®µå§‹ç»ˆä¸ºç©ºæ•°ç»„ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
        dmu_analysis["fabe_spi"] = []
        
        # 6. éªŒè¯å…³é”®å­—æ®µ
        if not dmu_analysis or (isinstance(dmu_analysis, dict) and not dmu_analysis):
            raise BusinessException("å…³é”®å­—æ®µæå–å¤±è´¥", "DMU_ANALYSIS_EMPTY")
        
        if not company_name or not company_name.strip():
            raise BusinessException("å…³é”®å­—æ®µæå–å¤±è´¥", "COMPANY_NAME_EMPTY")
        
        payload = {
            "dmu_analysis": dmu_analysis,
            "companyName": company_name
        }
        
        return {
            "success": True,
            "extracted_data": dmu_analysis,
            "database_payload": payload,
            "message": "ç»“æ„åŒ–æå–å®Œæˆ"
        }
    except BusinessException as e:
        return {
            "success": False,
            "error": e.message,
            "error_code": e.error_code,
            "extracted_data": None,
            "database_payload": None,
            "message": e.message
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "extracted_data": None,
            "database_payload": None,
            "message": str(e)
        }

